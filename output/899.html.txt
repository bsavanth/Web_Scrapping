date
tue
26
nov
1996
gmt
server
apache
1
1
dev
content
type
text
html
set
cookie
apache
gs35624184896967582
path
current
communications
research
laboratories
and
projects
information
theory
and
information
retrieval
graduate
students
n
leung
and
s
lawson
professors
j
t
coffey
and
s
sechrest
this
project
examines
the
fundamental
limits
of
efficient
context
based
retrieval
in
large
scale
databases
such
as
those
used
in
scientific
and
medical
databases
the
nature
and
quantity
of
the
data
involved
in
these
applications
demand
new
approaches
and
it
is
the
goal
of
this
project
to
investigate
the
role
that
the
methods
of
information
theory
can
play
in
this
task
based
on
a
number
of
simplified
abstract
models
we
have
derived
results
that
demonstrate
that
expected
access
time
can
be
greatly
reduced
in
general
by
adding
redundancy
to
the
database
the
general
problem
involves
a
number
of
interesting
variants
of
classical
problems
in
source
and
channel
coding
and
multi
user
information
theory
in
developing
theoretical
results
in
this
research
we
are
aiming
to
acquire
insight
that
will
be
used
to
provide
first
order
guidance
in
system
design
further
guidance
will
be
found
by
comparisons
with
results
arrived
at
through
more
detailed
simulation
of
systems
the
applicability
and
robustness
of
our
results
and
others
are
being
investigated
actual
datasets
and
realistic
workloads
can
be
used
to
validate
our
models
and
assess
the
applicability
of
our
results
to
physical
systems
maximum
likelihood
sequence
estimation
for
asynchronous
data
communications
graduate
student
i
sharfer
professor
a
o
hero
we
are
developing
techniques
for
maximum
likelihood
sequence
estimation
for
asynchronous
multiple
access
communications
with
coherent
spatial
diversity
using
a
receiver
antenna
array
this
project
involves
aspects
of
estimation
theory
and
lower
bound
analysis
iterative
implementations
of
maximum
likelihood
viterbi
and
em
algorithms
multiple
access
communications
and
antenna
array
processing
maximum
likelihood
beamforming
direction
finding
power
estimation
we
have
obtained
a
non
trivial
extension
of
the
snyder
georghiades
sequqnce
estimation
algorithm
to
the
array
receiever
which
includes
spread
spectrum
modulation
and
the
effects
of
rayleigh
fading
this
has
been
achieved
using
an
iterative
maximum
likelihood
algorithm
based
on
a
generalization
called
space
alternating
generalized
em
sage
of
the
expectation
maximization
em
algorithm
which
was
recently
developed
by
fessler
hero
for
problems
in
tomographic
reconstruction
the
resulting
sage
type
sequence
estimation
algorithm
yields
maximum
likelihood
estimates
which
are
of
much
lower
complexity
than
snyder
georghiades
involve
no
approximations
and
are
easily
generalizable
to
multipath
and
doppler
shift
common
in
mobile
radio
communications
research
papers
of
prof
d
l
neuhoff
and
his
students
at
the
eecs
dept
of
the
university
of
michigan
can
be
accessed
by
anonymous
ftp
to
ftp
eecs
umich
edu
in
the
directory
people
neuhoff
or
from
the
eecs
dept
network
the
path
is
n
ftp
f
people
neuhoff
structured
vector
quantization
and
asymptotic
quantization
theory
graduate
students
d
hui
a
balamesh
and
d
lyons
professor
d
l
neuhoff
sponsors
national
science
foundation
vector
quantization
is
increasingly
being
used
as
a
lossy
data
compression
technique
for
sources
such
as
speech
images
and
video
practical
vector
quantizers
structure
their
codebooks
to
simplify
encoding
and
decoding
for
example
block
transform
celp
tree
structured
two
stage
lattice
quadtree
product
pyramid
and
finite
state
vector
quantizers
are
common
techniques
listed
roughly
in
decreasing
order
of
structure
although
structure
generally
has
an
adverse
effect
on
rate
distortion
performance
it
permits
the
use
of
quantizers
with
larger
dimensions
which
usually
results
in
much
better
performance
for
a
given
complexity
until
now
there
has
been
little
theory
to
explain
the
complexity
performance
tradeoff
of
structured
vector
quantizers
this
project
is
developing
new
methods
for
analyzing
structured
vector
quantizers
one
is
an
extension
of
bennett
s
integral
to
vector
quantizers
it
shows
how
the
mean
squared
error
depends
on
the
distribution
and
shape
of
quantization
cells
another
is
an
asymptotic
formula
for
the
probability
density
of
the
quantization
error
these
new
methods
have
lead
to
the
successful
analysis
of
several
structured
vector
quantizers
including
tree
structured
and
two
stage
quantizers
still
another
is
the
analysis
of
transform
coders
at
very
low
rates
the
insight
gained
from
this
analysis
has
also
led
to
a
new
form
of
two
stage
quantization
called
cell
conditioned
multi
stage
vq
that
has
the
same
low
complexity
advantages
of
traditional
multi
stage
quantization
but
asymptotically
suffers
no
loss
in
performance
relative
to
unstructured
quantization
it
has
also
lead
to
new
high
performance
low
complexity
methods
for
converting
entropy
coders
into
fixed
rate
coders
model
based
digital
image
halftoning
professor
d
l
neuhoff
new
model
based
approaches
to
halftoning
are
being
developed
they
use
well
known
models
of
visual
perception
along
with
models
of
printing
that
we
have
developed
one
approach
minimizes
the
mean
squared
error
between
the
perceived
intensity
of
the
continuous
tone
image
and
the
perceived
intensity
of
the
printed
halftoned
image
another
is
an
adaptation
of
the
well
known
error
diffusion
method
to
include
the
printer
model
traditional
approaches
for
example
ordered
clustered
dither
obtain
robustness
to
printer
distortions
such
as
ink
spreading
at
the
expense
of
spatial
resolution
and
the
visibility
of
graininess
in
contrast
our
new
methods
exploit
the
printer
distortions
to
produce
higher
quality
images
than
would
be
obtained
with
rperfects
printers
improvements
due
to
model
based
halftoning
are
expected
to
reduce
the
resolution
requirements
for
laser
printers
used
in
high
quality
printing
e
g
400
dots
inch
instead
of
600
model
based
halftoning
can
be
especially
useful
in
transmission
of
high
quality
documents
using
high
fidelity
gray
scale
image
encoders
in
such
cases
halftoning
is
performed
at
the
receiver
just
before
printing
apart
from
coding
efficiency
this
approach
permits
the
halftoner
to
be
tuned
to
the
individual
printer
whose
characteristics
may
vary
considerably
from
those
of
other
printers
for
example
write
black
vs
write
white
laser
printers
image
coding
gracuate
students
m
horowitz
m
slyz
professor
d
l
neuhoff
image
coding
is
the
process
of
creating
binary
image
representations
with
the
dual
goals
of
efficiency
as
few
bits
as
possible
in
the
representation
and
accuracy
the
reproduced
images
shall
be
as
similar
as
possible
to
the
original
two
approaches
are
being
pursued
the
first
involves
the
use
of
a
detailed
model
of
the
intermediate
level
human
visual
sensors
to
construct
transform
codes
that
hide
quantization
noise
the
second
involves
the
design
of
lossless
image
codes
based
on
adaptive
prediction
with
new
kinds
of
predictors
and
adaptation
strategies
these
lossless
image
codes
are
intended
for
applications
such
as
medical
imaging
where
an
exact
reproduction
of
the
image
is
required
on
the
other
hand
the
first
project
is
intended
for
more
everyday
applications
where
exact
reproduction
is
not
necessary
but
good
quality
and
high
efficiency
are
needed
performance
and
complexity
of
cdma
networks
with
coded
modulation
graduate
students
m
klimesh
w
sung
professors
w
stark
and
j
t
coffey
sponsors
national
science
foundation
there
are
two
parts
of
this
research
project
the
first
part
deals
with
decoding
algorithms
for
worst
case
interference
in
this
work
we
have
derived
transmission
and
decoding
strategies
that
allows
for
maximum
information
transmission
or
minimum
error
probability
these
strategies
allow
the
transmitter
to
vary
the
transmission
power
pseudorandomly
the
performance
of
a
maximum
likelihood
decoding
algorithm
against
the
worst
case
jammer
can
be
improved
worst
case
interference
is
derived
as
well
as
the
resulting
performance
the
second
part
involves
developing
novel
decoders
and
demodulators
that
achieve
favorable
tradeoffs
of
complexity
versus
performance
within
this
area
a
number
of
current
topics
are
being
investigated
such
as
the
design
of
minimal
trellises
for
block
codes
fundamental
limits
for
decoders
with
a
reduced
number
of
states
decoding
algorithms
for
time
varying
channels
and
so
on
spread
spectrum
in
faded
channels
graduate
students
d
goeckel
and
v
chang
professor
w
stark
in
this
project
we
are
examining
the
performance
of
spread
spectrum
systems
in
a
faded
channel
the
type
of
fading
is
such
that
in
one
spread
spectrum
system
with
a
relatively
small
bandwidth
the
fading
appears
to
be
nonselective
in
frequency
in
another
spread
spectrum
system
the
fading
is
frequency
selective
the
goal
is
to
examine
the
performance
of
a
direct
sequence
spread
spectrum
system
operating
in
the
presence
of
multipath
fading
with
error
control
coding
the
important
issues
are
the
channels
memory
the
selectivity
of
the
channel
the
synchronization
algorithm
and
the
decoding
approach
these
are
issues
that
are
not
very
well
understood
by
system
designers
presently
our
preliminary
results
indicate
that
for
a
nonselective
channel
larger
spreading
improves
performance
in
spite
of
the
fact
that
more
of
the
received
energy
is
treated
as
interference
rather
than
part
of
a
faded
signal
in
other
words
as
the
bandwidth
increases
the
multipath
channel
becomes
more
resolveable
and
signals
that
were
unresolved
before
can
be
resolved
and
rejected
by
the
processing
gain
of
the
spread
spectrum
system
communicating
over
power
lines
graduate
student
y
p
wang
professor
w
stark
the
goal
of
this
research
is
to
investigate
different
alternatives
for
transmitting
data
over
a
power
line
the
power
line
suffers
from
distortion
because
of
the
nonideal
characteristics
of
the
media
this
comes
in
two
forms
the
first
is
due
to
the
attenuation
varying
as
a
function
of
frequency
the
second
form
is
multipath
due
to
reflections
off
of
mismatched
lines
transmitting
data
over
power
lines
using
spread
spectrum
techniques
can
mitigate
the
distortion
present
in
the
channel
we
are
investigating
different
modulation
and
coding
schemes
with
spread
spectrum
for
transmitting
data
over
the
power
line
optical
communications
and
very
noisy
channels
graduate
student
s
lee
professor
k
a
winick
a
very
noisy
channel
is
a
channel
whose
capacity
is
close
to
zero
very
noisy
channels
vncs
can
be
used
to
model
many
physical
channels
operating
at
low
signal
to
noise
ratios
more
importantly
a
large
class
of
physical
channels
operating
at
arbitrary
signal
to
noise
ratios
can
be
modeled
as
repeated
uses
of
a
vnc
in
particular
this
is
true
for
the
infinite
bandwidth
additive
white
gaussian
noise
channel
and
the
direct
detection
optical
poisson
channel
the
error
exponent
indicates
the
best
achievable
performance
of
any
block
codes
used
over
a
communications
channel
a
code
which
achieves
this
best
performance
is
said
to
be
exponentially
optimum
for
most
channels
the
error
exponent
is
not
known
and
can
only
be
bounded
in
this
research
the
error
exponent
is
computed
exactly
for
a
large
class
of
vncs
and
exponentially
optimum
codes
are
explicitly
constructed
for
these
channels
these
ideas
are
applied
to
derive
both
the
error
exponent
and
exponentially
optimum
codes
for
the
direct
detection
polarization
switched
optical
channel
distance
bounds
for
runlength
constrained
codes
graduate
student
s
h
yang
professor
k
a
winick
one
of
the
most
basic
problems
in
coding
theory
is
to
find
the
largest
code
of
a
given
length
and
minimum
distance
there
are
several
known
upper
and
lower
bounds
when
the
codewords
are
unconstrained
in
many
digital
transmission
and
recording
systems
considerations
such
as
spectral
shaping
self
clocking
and
reduction
of
intersymbol
interference
require
that
the
recorded
sequences
satisfy
special
run
length
constraints
in
this
research
distance
bounds
and
the
construction
of
runlength
constrained
error
correcting
codes
are
investigated
upper
bounds
are
derived
for
the
minimum
achievable
distance
of
runlength
constrained
sequences
and
lower
bounds
are
also
derived
which
include
cost
constraints
runlength
constrained
write
once
memories
graduate
student
s
h
yang
professor
k
a
winick
sponsors
office
of
naval
research
office
of
naval
technology
a
write
once
memory
wom
is
a
storage
medium
where
the
value
in
each
bit
location
can
only
be
changed
from
the
virgin
0
state
to
the
permanent
1
state
irreversibly
data
can
be
recorded
by
marking
blank
i
e
0
state
bits
those
marked
locations
are
stuck
in
the
1
state
and
hence
limit
to
some
degree
further
use
of
the
memory
examples
of
woms
in
the
electronic
and
computer
industry
are
punch
cards
paper
tapes
proms
and
optical
disks
current
laser
optics
technology
produces
the
write
once
cd
roms
that
are
especially
sutiable
for
storing
archival
data
usually
this
data
must
be
periodically
updated
after
it
has
been
initially
recorded
if
we
can
re
use
the
write
once
disk
by
implementing
an
efficient
coding
scheme
then
the
expense
of
replacing
the
whole
disk
may
be
saved
in
this
research
the
ultimate
capacity
of
runlength
constrained
write
once
memories
is
investigated
using
techniques
from
information
theory
corrugated
waveguide
filters
graduate
students
c
brooks
and
g
vossler
professor
k
a
winick
sponsor
national
science
foundation
corrugated
thin
film
waveguides
play
a
major
role
in
lightwave
devices
applications
include
distributed
feedback
lasing
bistable
switching
phase
matching
in
nonlinear
materials
pulse
compression
grating
coupling
and
optical
filtering
in
many
of
these
applications
the
corrugation
is
periodic
in
an
aperiodically
corrugated
thin
film
waveguide
however
the
frequency
dependent
coupling
between
waveguide
modes
can
be
used
to
produce
a
filter
which
has
a
specified
spectral
response
inverse
scattering
techniques
have
been
developed
for
designing
such
filters
and
efforts
are
currently
underway
to
fabricate
these
devices
several
new
fabrication
techniques
are
being
pursued
these
include
an
optical
direct
write
method
based
on
photobleaching
gamma
ray
induced
defect
centers
in
ion
exchangeable
glasses
and
a
rbent
waveguides
approach
the
first
filter
to
be
demonstrated
will
compensate
for
dispersion
induced
pulse
spreading
in
optical
fibers
rare
earth
doped
waveguide
lasers
graduate
students
g
vossler
and
c
brooks
professor
k
a
winick
sponsors
national
science
foundation
nsf
center
for
ultrafast
optical
science
smith
industries
imra
america
inc
recently
the
development
of
rare
earth
doped
fiber
lasers
has
received
considerable
attention
these
fiber
lasers
exhibit
a
host
of
desirable
properties
first
they
permit
wide
tuning
ranges
and
short
pulse
generation
because
of
their
broad
emission
lines
second
the
pump
powers
required
for
lasing
are
low
since
the
pump
beam
is
strongly
confined
to
a
small
volume
finally
rare
earth
doped
lasers
offer
better
frequency
stability
longer
lifetimes
and
less
temperature
sensitivity
than
semiconductor
devices
these
traits
make
them
promising
devices
for
telecommunications
sensing
and
spectroscopic
applications
glass
waveguide
lasers
on
planar
substrates
are
a
natural
extension
of
the
fiber
technology
as
opposed
to
a
fiber
it
should
be
possible
to
integrate
monolithically
multiple
components
onto
a
single
glass
substrate
these
components
could
include
distributed
feedback
laser
mirrors
grating
couplers
mode
lockers
and
nonlinear
elements
we
have
fabricated
neodymium
doped
channel
waveguide
lasers
in
special
glass
melts
and
have
demonstrated
the
first
glass
integrated
optic
distributed
bragg
reflector
laser
efforts
are
currently
under
way
to
passively
mode
lock
these
lasers
and
to
extend
theses
results
to
rare
earth
doped
lithium
niobate
hosts
novel
sensors
based
on
this
technology
are
also
under
development
return
to
um
eecs
systems
division
homepage
