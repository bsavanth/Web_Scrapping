date
tue
26
nov
1996
gmt
server
apache
1
2
dev
connection
close
content
type
text
html
last
modified
tue
03
sep
1996
gmt
etag
5
d872
3
cd8
322
c5c9a
content
length
15576
accept
ranges
bytes
vision
and
touch
guided
manipulation
vision
and
touch
guided
manipulation
group
mit
artificial
intelligence
lab
nonlinear
systems
lab
the
vision
and
touch
guided
manipulation
group
at
the
mit
artificial
intelligence
lab
conducts
research
in
a
wide
variety
of
topics
related
to
manipulator
and
end
effector
design
dextrous
manipulation
adaptive
nonlinear
control
and
vision
guided
manipulation
we
employ
techniques
from
various
fields
including
mechanical
design
stability
theory
machine
learning
approximation
theory
and
computer
vision
the
group
is
headed
by
dr
kenneth
salisbury
mechanics
and
professor
jean
jacques
e
slotine
autonomy
and
vision
other
groups
at
the
mit
ai
lab
headed
by
ken
are
the
haptic
interfaces
group
and
the
robot
hands
group
professor
slotine
also
heads
the
nonlinear
systems
laboratory
the
people
in
and
associated
with
the
vision
and
touch
guided
manipulation
group
are
brian
anthony
touch
sensing
mark
cannon
wavelet
networks
graduated
brian
eberman
system
integration
graduated
brian
hoffman
active
vision
w
jesse
hong
coordination
vision
manipulation
akhil
madhani
wrist
hand
mechanism
g
uumlnter
niemeyer
adaptive
control
and
system
integration
daniel
theobald
visual
processing
ichiro
watanabe
machine
learning
introduction
our
robots
our
research
references
introduction
to
our
robots
the
whole
arm
manipulator
the
mit
whole
arm
manipulator
wam
arm
is
a
very
fast
force
controllable
robot
arm
designed
in
dr
salisbury
s
group
at
the
ai
lab
the
concept
of
whole
arm
manipulation
was
originally
aimed
at
enabling
robots
to
use
all
of
their
surfaces
to
manipulate
and
perceive
objects
in
the
environment
central
to
this
concept
and
our
group
s
design
efforts
in
general
has
been
a
focus
on
controlling
the
forces
of
interaction
between
robots
and
the
environment
to
permit
this
the
wam
arm
employs
novel
cable
transmissions
which
are
stiff
low
friction
and
backdrivable
this
in
turn
permits
a
lightweight
design
to
achieve
good
bandwidth
in
force
control
while
in
contact
with
the
environment
the
arm
s
design
maximizes
the
lowest
resonant
frequency
of
the
system
and
employs
an
impedance
matching
ratio
between
motor
and
arm
masses
this
also
enables
the
arm
to
achieve
high
accelerations
while
moving
in
free
space
prof
slotine
and
his
students
have
developed
system
architectures
and
control
algorithms
for
both
force
controlled
tasks
and
tasks
requiring
rapid
and
accurate
free
space
motion
the
algorithms
also
provide
fast
and
stable
adaptation
of
the
arm
to
large
variations
in
loads
and
environments
the
talon
a
new
wrist
hand
mechanism
has
been
developed
and
replaces
a
previous
forearm
mounted
system
the
new
wrist
hand
known
as
the
talon
provides
3
additional
powered
freedoms
one
for
grasping
forces
and
two
for
orientation
the
motors
for
the
device
are
located
in
the
forearm
to
minimize
end
effector
mass
and
maximize
its
workspace
the
grasping
mechanism
is
comprised
of
a
group
of
2
fingers
which
move
against
a
group
of
3
fingers
such
that
two
groups
may
be
made
to
mesh
together
while
encircling
objects
finger
inner
surfaces
are
serrated
to
provide
for
high
contact
friction
against
rough
rock
surfaces
and
curved
to
enhance
capturing
large
and
small
objects
fingers
may
deflect
compliantly
to
accomodate
to
object
geometry
and
finger
deflections
may
be
sensed
to
provide
for
monitoring
grasp
state
we
also
have
studied
the
design
of
a
miniature
end
effector
suitable
for
grasping
small
rocks
and
cylindrical
objects
similar
in
spirit
to
the
talon
the
new
miniature
end
effector
utilizes
slightly
different
kinematics
to
enlarge
its
feasible
grasping
volume
the
fast
eye
gimbals
a
more
recent
component
of
our
system
is
our
active
vision
system
which
is
comprised
of
two
hi
resolution
color
ccd
cameras
with
50
mm
focal
length
lenses
mounted
on
two
degree
of
freedom
gimbals
we
have
utilized
cameras
with
a
narrow
field
of
view
to
give
higher
resolution
images
of
typical
objects
this
implies
however
that
the
cameras
have
to
be
actuated
in
order
to
pan
and
tilt
so
that
they
can
cover
broad
scenes
leading
to
an
active
vision
system
and
an
associated
trade
off
between
controller
precision
and
image
resolution
narrowness
of
field
of
view
the
actuators
which
we
have
implemented
were
designed
in
our
lab
and
are
known
as
the
fast
eye
gimbals
fegs
the
fegs
provide
directional
positioning
for
our
cameras
using
a
similar
drive
mechanism
as
the
wam
the
two
joints
are
cable
driven
and
have
ranges
of
motion
of
90
degrees
and
45
degrees
in
the
base
and
upper
joint
axes
respectively
these
two
fegs
are
currently
strategically
mounted
on
ceiling
rafters
with
a
wide
baseline
for
higher
position
accuracy
using
stereo
vision
methods
the
independent
nature
of
the
fegs
allow
us
to
position
each
one
at
different
locations
in
order
to
vary
the
baseline
or
orientation
of
the
coordinate
frame
as
well
as
easily
add
additional
cameras
to
provide
additional
perspectives
introduction
our
robots
our
research
references
research
projects
robust
grasping
in
unstructured
environments
one
of
our
current
projects
funded
by
nasa
jpl
is
to
develop
a
fundamental
understanding
of
the
problem
of
combining
real
time
vision
and
touch
sensor
data
with
robot
control
to
yield
robust
autonomous
and
semi
autonomous
grasping
and
grasp
stabilization
the
research
is
focused
on
providing
conceptual
and
experimental
support
of
planned
and
on
going
nasa
missions
utilizing
earth
orbiting
and
planetary
surface
robotics
we
have
implemented
a
high
speed
active
vision
system
a
multi
processor
operating
system
and
basic
algorithms
for
acquisition
and
grasp
of
stationary
spherical
and
cylindrical
objects
using
coordinated
robotic
vision
touch
sensing
and
control
preliminary
experiments
on
the
tracking
of
moving
objects
have
also
been
completed
concurrently
research
into
an
integrated
wrist
hand
design
used
for
performing
sensor
guided
grasps
and
a
preliminary
design
for
a
next
generation
miniature
end
effector
are
being
completed
robotic
catching
of
free
flying
objects
another
direction
of
our
research
funded
by
fujitsu
furukawa
and
the
sloan
foundation
is
to
accomplish
real
time
robust
catching
of
free
flying
objects
we
are
currently
focusing
on
spherical
balls
of
various
sizes
we
are
also
experimenting
with
additional
objects
with
different
dynamic
characteristics
such
as
sponge
balls
cylindrical
cans
and
paper
airplanes
our
system
uses
low
cost
vision
processing
hardware
for
simple
information
extraction
each
camera
signal
is
processed
independently
on
vision
boards
designed
by
other
members
of
the
mit
ai
laboratory
the
cognachrome
vision
tracking
system
these
vision
boards
provide
us
with
the
center
of
area
major
axis
number
of
pixels
and
aspect
ratio
of
the
color
keyed
image
the
two
fast
eye
gimbals
allow
us
to
locate
and
track
fast
randomly
moving
objects
using
kalman
like
filtering
methods
assuming
no
fixed
model
for
the
behavior
of
the
motion
independent
of
the
tracking
algorithms
we
use
least
squares
techniques
to
fit
polynomial
curves
to
prior
object
location
data
to
determine
the
future
path
with
this
knowledge
in
hand
we
can
calculate
a
path
for
the
wam
to
match
trajectories
with
the
object
to
accomplish
catching
and
smooth
object
wam
post
catching
deceleration
in
addition
to
the
basic
least
squares
techniques
for
path
prediction
we
study
experimentally
nonlinear
estimation
algorithms
to
give
long
term
real
time
prediction
of
the
path
of
moving
objects
with
the
goal
of
robust
acquisition
the
algorithms
are
based
on
stable
on
line
construction
of
approximation
networks
composed
of
state
space
basis
functions
localized
in
both
space
and
spatial
frequency
as
a
initial
step
we
have
studied
the
network
s
performance
in
predicting
the
path
of
light
objects
thrown
in
air
further
application
may
include
motion
prediction
of
objects
rolling
bouncing
or
breaking
up
on
rough
terrains
some
recent
successful
results
for
the
application
of
this
network
have
been
obtain
in
catching
of
sponge
balls
and
even
paper
airplanes
click
to
view
wam
catching
click
to
view
wam
airplane
catching
copy
1995
photo
courtesy
of
hank
morgan
introduction
our
robots
our
research
references
partial
list
of
references
autonomous
rock
acquisition
d
a
theobald
w
j
hong
a
madhani
b
hoffman
g
niemeyer
l
cadapan
j
j
e
slotine
j
k
salisbury
proceedings
of
the
aiaa
forum
on
advanced
development
in
space
robotics
madison
wisconsin
august
1
2
1996
experiments
in
hand
eye
coordination
using
active
vision
w
hong
and
j
j
e
slotine
proceedings
of
the
fourth
international
symposium
on
experimental
robotics
iser
95
stanford
california
june
30
july
2
1995
robotic
catching
and
manipulation
using
active
vision
w
hong
m
s
thesis
department
of
mechanical
engineering
mit
september
1995
space
frequency
localized
basis
function
networks
for
nonlinear
system
estimation
and
control
m
cannon
and
j
j
e
slotine
neurocomputing
9
3
1995
adaptive
visual
tracking
and
gaussian
network
algorithms
for
robotic
catching
h
kimura
and
j
j
e
slotine
dsc
vol
43
advances
in
robust
and
nonlinear
control
systems
winter
annual
meeting
of
the
asme
anaheim
ca
pp
67
74
november
1992
experiments
in
robotic
catching
b
m
hove
and
j
j
e
slotine
proceedings
of
the
1991
american
control
conference
vol
1
boston
ma
pp
380
385
june
1991
performance
in
adaptive
manipulator
control
g
niemeyer
and
j
j
e
slotine
international
journal
of
robotics
research
10
2
december
1988
preliminary
design
of
a
whole
arm
manipulation
system
wam
j
k
salisbury
w
t
townsend
b
s
eberman
d
m
dipietro
proceedings
1988
ieee
international
conference
on
robotics
and
automation
philadelphia
pa
april
1988
the
effect
of
transmission
design
on
force
controlled
manipulator
performance
w
t
townsend
phd
thesis
department
of
mechanical
engineering
mit
april
1988
see
also
mit
ai
lab
technical
report
1054
whole
arm
manipulation
j
k
salisbury
proceedings
4
th
international
symposium
on
robotics
research
santa
cruz
ca
august
1987
design
and
control
of
a
two
axis
gimbal
system
for
use
in
active
vision
n
swarup
s
b
thesis
dept
of
mechanical
engineering
mit
cambridge
ma
1993
a
high
speed
low
latency
portable
vision
sensing
system
a
wright
spie
september
1993
introduction
our
robots
our
research
references
maintainer
jesse
ai
mit
edu
comments
to
wam
ai
mit
edu
last
updated
mon
aug
26
edt
1996
jesse
ai
mit
edu
copy
1996
all
rights
reserved
